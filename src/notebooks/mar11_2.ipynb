{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "d70f47ef-8793-40f0-a24a-73531e2c8a85",
        "_uuid": "9853586a0dc75ce39e7c7ffcde1eb4d47c6fb02e"
      },
      "cell_type": "markdown",
      "source": "## Overview ##\n\nBased on Starter Kernel [Logistic Regression on Tournament Seeds by Kasper P. Lauritzen](https://www.kaggle.com/kplauritzen/notebookde27b18258?scriptVersionId=804590) "
    },
    {
      "metadata": {
        "_cell_guid": "0c233e05-c63d-4866-96dc-bb38d444bf84",
        "_uuid": "5464dc4b196dc4c8dd0323bbd71b75724113e2af",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import GridSearchCV\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom subprocess import check_output\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\n\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "05f13f0b-e969-45a5-a05b-694cb388a056",
        "_uuid": "819472385a23f3fd5aaf4172b4f8db227cf5271f"
      },
      "cell_type": "markdown",
      "source": "## Load the training data ##\nWe're keeping it simple & using only 2 files for this model: the Tourney seeds & Compact results."
    },
    {
      "metadata": {
        "_cell_guid": "aafa51a3-6f36-4469-8041-6741b275254e",
        "_uuid": "bf8ee168a0372e883332d6bb0ce5c89c13143650",
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_dir = '../input/'\ndf_seeds = pd.read_csv(data_dir + 'NCAATourneySeeds.csv')\n#df_tour = pd.read_csv(data_dir + 'NCAATourneyDetailedResults.csv')\ndf_tour = pd.read_csv(data_dir + 'RegularSeasonCompactResults.csv')\nteams = pd.read_csv(data_dir + 'Teams.csv')\n\ndef seed_to_int(seed):\n    s_int = int(seed[1:3])\n    return s_int\ndf_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\ndf_seeds.drop(labels=['Seed'], inplace=True, axis=1) # This is the string label\ndf_tour.drop(labels=['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], inplace=True, axis=1)\ndf_tour.head()\n",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 133,
          "data": {
            "text/plain": "   Season  WTeamID  LTeamID\n0    1985     1228     1328\n1    1985     1106     1354\n2    1985     1112     1223\n3    1985     1165     1432\n4    1985     1192     1447",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Season</th>\n      <th>WTeamID</th>\n      <th>LTeamID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1985</td>\n      <td>1228</td>\n      <td>1328</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1985</td>\n      <td>1106</td>\n      <td>1354</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1985</td>\n      <td>1112</td>\n      <td>1223</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1985</td>\n      <td>1165</td>\n      <td>1432</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985</td>\n      <td>1192</td>\n      <td>1447</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ebb26984-709f-4f62-925e-16b2ea1226d2",
        "_uuid": "da8de9fda8a9e8d7bd7cea13c83a1139ade69a2f"
      },
      "cell_type": "markdown",
      "source": "Build out the id string (year_wteam_lteam)\nCreate a prediction at the end."
    },
    {
      "metadata": {
        "_cell_guid": "3b727e85-b452-4d27-a197-d437499f6a5c",
        "_kg_hide-output": false,
        "_uuid": "a6f3a5658dbe11d62526d90bfaaa8f5b23dea2bd",
        "_kg_hide-input": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_winseeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\ndf_lossseeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\ndf_dummy = pd.merge(left=df_tour, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\ndf_concat = pd.merge(left=df_dummy, right=df_lossseeds, on=['Season', 'LTeamID'])\ndf_true=df_concat.copy()\n\ncolumnsTitles=[\"LTeamID\",\"WTeamID\"]\ndf_false = df_concat.rename(columns={'WTeamID': 'LTeamID_', 'LTeamID': 'WTeamID_'}) #idk if i have to do this I just didnt want to create issues\ndf_false = df_false.rename(columns={'LTeamID_': 'LTeamID', 'WTeamID_': 'WTeamID'})\ndf_false = df_false.rename(columns={'WSeed': 'LSeed_', 'LSeed': 'WSeed_'}) #idk if i have to do this I just didnt want to create issues\ndf_false = df_false.rename(columns={'LSeed_': 'LSeed', 'WSeed_': 'WSeed'})\n\n\ndf_true['label'] = 1\ndf_false['label'] = 0\n\ndf = df_true.append(df_false, ignore_index=True)\ndf = df.fillna(17)\n\n#df['WTID']=df.apply(build_wteamyear, axis=1) #again, probably better way to do this and save a function\n#df['LTID']=df.apply(build_lteamyear, axis=1)\ndf['SeedDiff'] =  df.WSeed - df.LSeed #Lower seeds are better, so Negative means that the lower seed team won.\ndf = df[df['Season'] > 2013] # We want to train on 2014 and above.\n\ndf = df[['WTeamID', 'LTeamID', 'SeedDiff', 'label']]\ndf.head()\n\n",
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 159,
          "data": {
            "text/plain": "       WTeamID  LTeamID  SeedDiff  label\n15289     1103     1157       1.0      1\n15290     1279     1157       1.0      1\n15291     1278     1157       1.0      1\n15292     1418     1157      -2.0      1\n15293     1155     1157       1.0      1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WTeamID</th>\n      <th>LTeamID</th>\n      <th>SeedDiff</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15289</th>\n      <td>1103</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15290</th>\n      <td>1279</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15291</th>\n      <td>1278</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15292</th>\n      <td>1418</td>\n      <td>1157</td>\n      <td>-2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15293</th>\n      <td>1155</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c8fd85d7-782a-4370-ba22-61b53fa9fe8a",
        "_uuid": "0d146d07c99b9b4fdcde96e7fe3aff1d8382d8cd"
      },
      "cell_type": "markdown",
      "source": "## Encode and, Scale and Split ##"
    },
    {
      "metadata": {
        "_cell_guid": "14d21c09-afdc-4c8a-ad6e-ac7ccf216c3d",
        "_uuid": "1a9c7352e5baa2fb64c528503d58ddcd8ab5004c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "X = df.iloc[:, 0:3].values\ny = df.iloc[:, 3].values\n\n\nenc_1 = LabelEncoder()\nX[:, 0] = enc_1.fit_transform(X[:, 0])\nenc_2 = LabelEncoder()\nX[:, 1] = enc_2.fit_transform(X[:, 1])\nonehotencoder = OneHotEncoder(categorical_features = [0,1],handle_unknown='error') #handle_unknown='unknown'or impute\nX = onehotencoder.fit_transform(X).toarray()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nds_width=X_test.shape[1]\n",
      "execution_count": 160,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "595df905-c0af-4cd9-88f2-1f7f7b68dee2",
        "_uuid": "25cfee848688706e19c91fbc45bce80338b4be85"
      },
      "cell_type": "markdown",
      "source": "## Build the classifier and hit the button ##"
    },
    {
      "metadata": {
        "_cell_guid": "ea1b2af7-d688-42d7-91a3-0e6414e4c701",
        "_uuid": "847d46c9b67f30410852520d0afe5b1cb0b6b72a",
        "scrolled": false,
        "trusted": true,
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "from keras.layers import LeakyReLU\nfrom keras import metrics\nfrom keras import optimizers\n\n# 61%  //Dense(6, he_normal)//leakyrelu alpha 0.2//Dense(16, he_normal)\n# leakyrelu alpha 0.2//Dense(16, he_normal)//leakyrelu alpha 0.2//Dense(1, he_normal, sigmoid)//SGD, Mean_Squared_Error\n# Third Attempt.\nclassifier = Sequential()\nclassifier.add(Dense(6,input_shape=(ds_width,),kernel_initializer = 'normal',activation='relu'))\n#classifier.add(LeakyReLU(alpha=0.2))\nclassifier.add(Dense(13, activation='relu',kernel_initializer = 'normal',))\n#classifier.add(LeakyReLU(alpha=0.2))\nclassifier.add(Dense(13, activation='relu',kernel_initializer = 'normal',))\nclassifier.add(Dense(1,kernel_initializer = 'normal' ))\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['binary_accuracy']) #binary_crossentropy\nprint(\"Cooking... Please wait\")\nclassifier.fit(X_train, y_train, batch_size = 250, epochs = 500, verbose=1)\nprint(\"*ding*... Testing Accuracy on test set\")\n#Run Predictions on the test set\npred_test = classifier.predict(X_test)\n\npred_test = (pred_test > 0.5)\ncm = confusion_matrix(pred_test, y_test)\nprint ((cm[0][0]+cm[1][1])/(sum(cm[0])+sum(cm[1])))",
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Cooking... Please wait\nEpoch 1/500\n3891/3891 [==============================] - 4s 964us/step - loss: 2.5723 - binary_accuracy: 0.5009\nEpoch 2/500\n3891/3891 [==============================] - 0s 20us/step - loss: 1.8436 - binary_accuracy: 0.5009\nEpoch 3/500\n3891/3891 [==============================] - 0s 23us/step - loss: 1.5649 - binary_accuracy: 0.5009\nEpoch 4/500\n3891/3891 [==============================] - 0s 20us/step - loss: 1.2945 - binary_accuracy: 0.5009\nEpoch 5/500\n3891/3891 [==============================] - 0s 26us/step - loss: 1.0318 - binary_accuracy: 0.5012\nEpoch 6/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.8059 - binary_accuracy: 0.5307\nEpoch 7/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.6410 - binary_accuracy: 0.6076\nEpoch 8/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.5550 - binary_accuracy: 0.6831\nEpoch 9/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.5200 - binary_accuracy: 0.7032\nEpoch 10/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.4974 - binary_accuracy: 0.7132\nEpoch 11/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.4812 - binary_accuracy: 0.7186\nEpoch 12/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.4675 - binary_accuracy: 0.7265\nEpoch 13/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.4572 - binary_accuracy: 0.7301\nEpoch 14/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.4489 - binary_accuracy: 0.7355\nEpoch 15/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.4411 - binary_accuracy: 0.7350\nEpoch 16/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.4346 - binary_accuracy: 0.7343\nEpoch 17/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.4283 - binary_accuracy: 0.7371\nEpoch 18/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.4229 - binary_accuracy: 0.7327\nEpoch 19/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.4175 - binary_accuracy: 0.7312\nEpoch 20/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.4123 - binary_accuracy: 0.7281\nEpoch 21/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.4075 - binary_accuracy: 0.7232\nEpoch 22/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.4037 - binary_accuracy: 0.7230\nEpoch 23/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.3990 - binary_accuracy: 0.7237\nEpoch 24/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.3950 - binary_accuracy: 0.7181\nEpoch 25/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.3915 - binary_accuracy: 0.7127\nEpoch 26/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.3875 - binary_accuracy: 0.7075\nEpoch 27/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.3839 - binary_accuracy: 0.7032\nEpoch 28/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.3801 - binary_accuracy: 0.6980\nEpoch 29/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.3765 - binary_accuracy: 0.6942\nEpoch 30/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.3728 - binary_accuracy: 0.6908\nEpoch 31/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3695 - binary_accuracy: 0.6875\nEpoch 32/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3666 - binary_accuracy: 0.6870\nEpoch 33/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.3636 - binary_accuracy: 0.6839\nEpoch 34/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.3604 - binary_accuracy: 0.6831\nEpoch 35/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.3574 - binary_accuracy: 0.6813\nEpoch 36/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.3545 - binary_accuracy: 0.6803\nEpoch 37/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.3521 - binary_accuracy: 0.6798\nEpoch 38/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.3494 - binary_accuracy: 0.6821\nEpoch 39/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.3467 - binary_accuracy: 0.6769\nEpoch 40/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.3438 - binary_accuracy: 0.6803\nEpoch 41/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.3414 - binary_accuracy: 0.6777\nEpoch 42/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.3397 - binary_accuracy: 0.6736\nEpoch 43/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.3369 - binary_accuracy: 0.6764\nEpoch 44/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.3347 - binary_accuracy: 0.6767\nEpoch 45/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.3329 - binary_accuracy: 0.6757\nEpoch 46/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.3307 - binary_accuracy: 0.6780\nEpoch 47/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.3292 - binary_accuracy: 0.6757\nEpoch 48/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3265 - binary_accuracy: 0.6741\nEpoch 49/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3255 - binary_accuracy: 0.6728\nEpoch 50/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.3231 - binary_accuracy: 0.6741\nEpoch 51/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3210 - binary_accuracy: 0.6723\nEpoch 52/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3194 - binary_accuracy: 0.6749\nEpoch 53/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.3178 - binary_accuracy: 0.6708\nEpoch 54/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.3161 - binary_accuracy: 0.6723\nEpoch 55/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.3143 - binary_accuracy: 0.6703\nEpoch 56/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.3131 - binary_accuracy: 0.6674\nEpoch 57/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.3115 - binary_accuracy: 0.6692\nEpoch 58/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3103 - binary_accuracy: 0.6705\nEpoch 59/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.3088 - binary_accuracy: 0.6726\nEpoch 60/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.3079 - binary_accuracy: 0.6687\nEpoch 61/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.3063 - binary_accuracy: 0.6713\nEpoch 62/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3052 - binary_accuracy: 0.6703\nEpoch 63/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.3035 - binary_accuracy: 0.6715\nEpoch 64/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.3024 - binary_accuracy: 0.6682\nEpoch 65/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.3015 - binary_accuracy: 0.6664\nEpoch 66/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.3008 - binary_accuracy: 0.6649\nEpoch 67/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2999 - binary_accuracy: 0.6685\nEpoch 68/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2987 - binary_accuracy: 0.6687\nEpoch 69/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2968 - binary_accuracy: 0.6695\nEpoch 70/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2961 - binary_accuracy: 0.6687\nEpoch 71/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2957 - binary_accuracy: 0.6664\nEpoch 72/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2953 - binary_accuracy: 0.6659\nEpoch 73/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2927 - binary_accuracy: 0.6680\nEpoch 74/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 25us/step - loss: 0.2924 - binary_accuracy: 0.6641\nEpoch 75/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2917 - binary_accuracy: 0.6659\nEpoch 76/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2905 - binary_accuracy: 0.6667\nEpoch 77/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2897 - binary_accuracy: 0.6654\nEpoch 78/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2891 - binary_accuracy: 0.6667\nEpoch 79/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2883 - binary_accuracy: 0.6662\nEpoch 80/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2876 - binary_accuracy: 0.6641\nEpoch 81/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.2879 - binary_accuracy: 0.6605\nEpoch 82/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2866 - binary_accuracy: 0.6651\nEpoch 83/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2856 - binary_accuracy: 0.6682\nEpoch 84/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2844 - binary_accuracy: 0.6623\nEpoch 85/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2841 - binary_accuracy: 0.6623\nEpoch 86/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2833 - binary_accuracy: 0.6672\nEpoch 87/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2823 - binary_accuracy: 0.6664\nEpoch 88/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2830 - binary_accuracy: 0.6641: 0s - loss: 0.2788 - binary_accuracy: 0.657\nEpoch 89/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2804 - binary_accuracy: 0.6644\nEpoch 90/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2804 - binary_accuracy: 0.6667\nEpoch 91/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2805 - binary_accuracy: 0.6651\nEpoch 92/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2809 - binary_accuracy: 0.6600\nEpoch 93/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2788 - binary_accuracy: 0.6623\nEpoch 94/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2777 - binary_accuracy: 0.6628\nEpoch 95/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2778 - binary_accuracy: 0.6626\nEpoch 96/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2772 - binary_accuracy: 0.6659\nEpoch 97/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2762 - binary_accuracy: 0.6628\nEpoch 98/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2758 - binary_accuracy: 0.6584\nEpoch 99/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.2756 - binary_accuracy: 0.6605\nEpoch 100/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2756 - binary_accuracy: 0.6590\nEpoch 101/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2782 - binary_accuracy: 0.6659\nEpoch 102/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2751 - binary_accuracy: 0.6618\nEpoch 103/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.2743 - binary_accuracy: 0.6602\nEpoch 104/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2745 - binary_accuracy: 0.6631\nEpoch 105/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2728 - binary_accuracy: 0.6610\nEpoch 106/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2715 - binary_accuracy: 0.6618\nEpoch 107/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2710 - binary_accuracy: 0.6618\nEpoch 108/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2698 - binary_accuracy: 0.6613\nEpoch 109/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2700 - binary_accuracy: 0.6646\nEpoch 110/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2691 - binary_accuracy: 0.6613\nEpoch 111/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2691 - binary_accuracy: 0.6595\nEpoch 112/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2680 - binary_accuracy: 0.6590\nEpoch 113/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2674 - binary_accuracy: 0.6628\nEpoch 114/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2674 - binary_accuracy: 0.6608\nEpoch 115/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2661 - binary_accuracy: 0.6610\nEpoch 116/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2663 - binary_accuracy: 0.6595\nEpoch 117/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2653 - binary_accuracy: 0.6584\nEpoch 118/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2648 - binary_accuracy: 0.6584\nEpoch 119/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2668 - binary_accuracy: 0.6590\nEpoch 120/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2636 - binary_accuracy: 0.6590\nEpoch 121/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2684 - binary_accuracy: 0.6569\nEpoch 122/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2674 - binary_accuracy: 0.6597\nEpoch 123/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2667 - binary_accuracy: 0.6543\nEpoch 124/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2660 - binary_accuracy: 0.6572\nEpoch 125/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2662 - binary_accuracy: 0.6577\nEpoch 126/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2650 - binary_accuracy: 0.6574\nEpoch 127/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2657 - binary_accuracy: 0.6582\nEpoch 128/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2662 - binary_accuracy: 0.6592\nEpoch 129/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2655 - binary_accuracy: 0.6584\nEpoch 130/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2711 - binary_accuracy: 0.6548\nEpoch 131/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2684 - binary_accuracy: 0.6572\nEpoch 132/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2684 - binary_accuracy: 0.6574\nEpoch 133/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2665 - binary_accuracy: 0.6572\nEpoch 134/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2665 - binary_accuracy: 0.6559\nEpoch 135/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2666 - binary_accuracy: 0.6538\nEpoch 136/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2662 - binary_accuracy: 0.6556\nEpoch 137/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2648 - binary_accuracy: 0.6543\nEpoch 138/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2658 - binary_accuracy: 0.6546\nEpoch 139/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2651 - binary_accuracy: 0.6561\nEpoch 140/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2662 - binary_accuracy: 0.6533\nEpoch 141/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2656 - binary_accuracy: 0.6492\nEpoch 142/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2640 - binary_accuracy: 0.6530\nEpoch 143/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2645 - binary_accuracy: 0.6536\nEpoch 144/500\n3891/3891 [==============================] - 0s 31us/step - loss: 0.2638 - binary_accuracy: 0.6546\nEpoch 145/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2627 - binary_accuracy: 0.6551\nEpoch 146/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 26us/step - loss: 0.2631 - binary_accuracy: 0.6530\nEpoch 147/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2629 - binary_accuracy: 0.6530\nEpoch 148/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2618 - binary_accuracy: 0.6510\nEpoch 149/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2622 - binary_accuracy: 0.6530\nEpoch 150/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2612 - binary_accuracy: 0.6543\nEpoch 151/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2614 - binary_accuracy: 0.6551\nEpoch 152/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2611 - binary_accuracy: 0.6538\nEpoch 153/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2619 - binary_accuracy: 0.6500\nEpoch 154/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2608 - binary_accuracy: 0.6541\nEpoch 155/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2615 - binary_accuracy: 0.6505\nEpoch 156/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2611 - binary_accuracy: 0.6518\nEpoch 157/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2606 - binary_accuracy: 0.6525\nEpoch 158/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2606 - binary_accuracy: 0.6548\nEpoch 159/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2605 - binary_accuracy: 0.6538\nEpoch 160/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2594 - binary_accuracy: 0.6518\nEpoch 161/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2605 - binary_accuracy: 0.6512\nEpoch 162/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2606 - binary_accuracy: 0.6464\nEpoch 163/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2597 - binary_accuracy: 0.6500\nEpoch 164/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2596 - binary_accuracy: 0.6541\nEpoch 165/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2589 - binary_accuracy: 0.6515\nEpoch 166/500\n3891/3891 [==============================] - 0s 30us/step - loss: 0.2591 - binary_accuracy: 0.6505\nEpoch 167/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2586 - binary_accuracy: 0.6505\nEpoch 168/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2588 - binary_accuracy: 0.6489\nEpoch 169/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2576 - binary_accuracy: 0.6523\nEpoch 170/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2571 - binary_accuracy: 0.6523\nEpoch 171/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2570 - binary_accuracy: 0.6538\nEpoch 172/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2569 - binary_accuracy: 0.6492\nEpoch 173/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2568 - binary_accuracy: 0.6507\nEpoch 174/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2574 - binary_accuracy: 0.6456\nEpoch 175/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2573 - binary_accuracy: 0.6510\nEpoch 176/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2578 - binary_accuracy: 0.6502\nEpoch 177/500\n3891/3891 [==============================] - 0s 32us/step - loss: 0.2563 - binary_accuracy: 0.6502\nEpoch 178/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2562 - binary_accuracy: 0.6489\nEpoch 179/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2566 - binary_accuracy: 0.6530\nEpoch 180/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2562 - binary_accuracy: 0.6507\nEpoch 181/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2566 - binary_accuracy: 0.6438\nEpoch 182/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2565 - binary_accuracy: 0.6494\nEpoch 183/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2548 - binary_accuracy: 0.6530\nEpoch 184/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2551 - binary_accuracy: 0.6500\nEpoch 185/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2558 - binary_accuracy: 0.6466\nEpoch 186/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2585 - binary_accuracy: 0.6494\nEpoch 187/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2587 - binary_accuracy: 0.6469\nEpoch 188/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2557 - binary_accuracy: 0.6476\nEpoch 189/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2545 - binary_accuracy: 0.6494\nEpoch 190/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2537 - binary_accuracy: 0.6461\nEpoch 191/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2546 - binary_accuracy: 0.6505\nEpoch 192/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2538 - binary_accuracy: 0.6492\nEpoch 193/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2533 - binary_accuracy: 0.6474\nEpoch 194/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2576 - binary_accuracy: 0.6451\nEpoch 195/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2581 - binary_accuracy: 0.6438\nEpoch 196/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2558 - binary_accuracy: 0.6520\nEpoch 197/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2537 - binary_accuracy: 0.6471\nEpoch 198/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2541 - binary_accuracy: 0.6479\nEpoch 199/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2521 - binary_accuracy: 0.6487\nEpoch 200/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2513 - binary_accuracy: 0.6482\nEpoch 201/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2505 - binary_accuracy: 0.6446\nEpoch 202/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2511 - binary_accuracy: 0.6448\nEpoch 203/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2531 - binary_accuracy: 0.6453\nEpoch 204/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2568 - binary_accuracy: 0.6453\nEpoch 205/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2595 - binary_accuracy: 0.6417\nEpoch 206/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2597 - binary_accuracy: 0.6471\nEpoch 207/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2606 - binary_accuracy: 0.6458\nEpoch 208/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2605 - binary_accuracy: 0.6443\nEpoch 209/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2580 - binary_accuracy: 0.6469\nEpoch 210/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2591 - binary_accuracy: 0.6471\nEpoch 211/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2597 - binary_accuracy: 0.6453\nEpoch 212/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2642 - binary_accuracy: 0.6474\nEpoch 213/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2652 - binary_accuracy: 0.6469\nEpoch 214/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2641 - binary_accuracy: 0.6456\nEpoch 215/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2665 - binary_accuracy: 0.6392\nEpoch 216/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2677 - binary_accuracy: 0.6412\nEpoch 217/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2663 - binary_accuracy: 0.6448\nEpoch 218/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 21us/step - loss: 0.2676 - binary_accuracy: 0.6415\nEpoch 219/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2676 - binary_accuracy: 0.6389\nEpoch 220/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2650 - binary_accuracy: 0.6438\nEpoch 221/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2662 - binary_accuracy: 0.6428\nEpoch 222/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2665 - binary_accuracy: 0.6389\nEpoch 223/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2662 - binary_accuracy: 0.6435\nEpoch 224/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2660 - binary_accuracy: 0.6420\nEpoch 225/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2658 - binary_accuracy: 0.6399\nEpoch 226/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2667 - binary_accuracy: 0.6392\nEpoch 227/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2664 - binary_accuracy: 0.6381\nEpoch 228/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2667 - binary_accuracy: 0.6405\nEpoch 229/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2678 - binary_accuracy: 0.6397\nEpoch 230/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2729 - binary_accuracy: 0.6430\nEpoch 231/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2665 - binary_accuracy: 0.6448\nEpoch 232/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2663 - binary_accuracy: 0.6420\nEpoch 233/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2651 - binary_accuracy: 0.6407\nEpoch 234/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2652 - binary_accuracy: 0.6384\nEpoch 235/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2653 - binary_accuracy: 0.6410\nEpoch 236/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2648 - binary_accuracy: 0.6379\nEpoch 237/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2644 - binary_accuracy: 0.6384\nEpoch 238/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2644 - binary_accuracy: 0.6402\nEpoch 239/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2650 - binary_accuracy: 0.6389\nEpoch 240/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2630 - binary_accuracy: 0.6394\nEpoch 241/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2624 - binary_accuracy: 0.6374\nEpoch 242/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2621 - binary_accuracy: 0.6381\nEpoch 243/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2650 - binary_accuracy: 0.6353\nEpoch 244/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2643 - binary_accuracy: 0.6330\nEpoch 245/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2632 - binary_accuracy: 0.6376\nEpoch 246/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2627 - binary_accuracy: 0.6371\nEpoch 247/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2627 - binary_accuracy: 0.6425\nEpoch 248/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2641 - binary_accuracy: 0.6381\nEpoch 249/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.4472 - binary_accuracy: 0.6309\nEpoch 250/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.9104 - binary_accuracy: 0.6155\nEpoch 251/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.4673 - binary_accuracy: 0.6335\nEpoch 252/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.3756 - binary_accuracy: 0.6476\nEpoch 253/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.3583 - binary_accuracy: 0.6492\nEpoch 254/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.3246 - binary_accuracy: 0.6546\nEpoch 255/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.3111 - binary_accuracy: 0.6523\nEpoch 256/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2943 - binary_accuracy: 0.6590\nEpoch 257/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2848 - binary_accuracy: 0.6610\nEpoch 258/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2835 - binary_accuracy: 0.6662\nEpoch 259/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2783 - binary_accuracy: 0.6687\nEpoch 260/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2761 - binary_accuracy: 0.6698\nEpoch 261/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2736 - binary_accuracy: 0.6682\nEpoch 262/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2721 - binary_accuracy: 0.6669\nEpoch 263/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2704 - binary_accuracy: 0.6674\nEpoch 264/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2693 - binary_accuracy: 0.6656\nEpoch 265/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2679 - binary_accuracy: 0.6659\nEpoch 266/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2675 - binary_accuracy: 0.6654\nEpoch 267/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2664 - binary_accuracy: 0.6659\nEpoch 268/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2655 - binary_accuracy: 0.6633\nEpoch 269/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2649 - binary_accuracy: 0.6631\nEpoch 270/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2649 - binary_accuracy: 0.6610\nEpoch 271/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.2638 - binary_accuracy: 0.6610\nEpoch 272/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2634 - binary_accuracy: 0.6654\nEpoch 273/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2631 - binary_accuracy: 0.6649\nEpoch 274/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2623 - binary_accuracy: 0.6638\nEpoch 275/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2618 - binary_accuracy: 0.6636\nEpoch 276/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2614 - binary_accuracy: 0.6628\nEpoch 277/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2608 - binary_accuracy: 0.6618\nEpoch 278/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2608 - binary_accuracy: 0.6631\nEpoch 279/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2600 - binary_accuracy: 0.6659\nEpoch 280/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2596 - binary_accuracy: 0.6646\nEpoch 281/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2591 - binary_accuracy: 0.6659\nEpoch 282/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2588 - binary_accuracy: 0.6649\nEpoch 283/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2587 - binary_accuracy: 0.6649\nEpoch 284/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2584 - binary_accuracy: 0.6649\nEpoch 285/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2587 - binary_accuracy: 0.6628: 0s - loss: 0.2606 - binary_accuracy: 0.663\nEpoch 286/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2588 - binary_accuracy: 0.6659\nEpoch 287/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2594 - binary_accuracy: 0.6677\nEpoch 288/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2584 - binary_accuracy: 0.6662\nEpoch 289/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2579 - binary_accuracy: 0.6659\nEpoch 290/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 21us/step - loss: 0.2574 - binary_accuracy: 0.6651\nEpoch 291/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2571 - binary_accuracy: 0.6646\nEpoch 292/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2568 - binary_accuracy: 0.6638\nEpoch 293/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2565 - binary_accuracy: 0.6638\nEpoch 294/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2565 - binary_accuracy: 0.6636\nEpoch 295/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2561 - binary_accuracy: 0.6654\nEpoch 296/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2558 - binary_accuracy: 0.6631\nEpoch 297/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2556 - binary_accuracy: 0.6605\nEpoch 298/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2556 - binary_accuracy: 0.6628\nEpoch 299/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2551 - binary_accuracy: 0.6633\nEpoch 300/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2552 - binary_accuracy: 0.6620\nEpoch 301/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2547 - binary_accuracy: 0.6613\nEpoch 302/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2546 - binary_accuracy: 0.6631\nEpoch 303/500\n3891/3891 [==============================] - 0s 30us/step - loss: 0.2548 - binary_accuracy: 0.6618\nEpoch 304/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2545 - binary_accuracy: 0.6608\nEpoch 305/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2542 - binary_accuracy: 0.6592\nEpoch 306/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2540 - binary_accuracy: 0.6608\nEpoch 307/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2538 - binary_accuracy: 0.6613\nEpoch 308/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2538 - binary_accuracy: 0.6623\nEpoch 309/500\n3891/3891 [==============================] - 0s 30us/step - loss: 0.2535 - binary_accuracy: 0.6610\nEpoch 310/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2536 - binary_accuracy: 0.6597\nEpoch 311/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2541 - binary_accuracy: 0.6597\nEpoch 312/500\n3891/3891 [==============================] - 0s 30us/step - loss: 0.2534 - binary_accuracy: 0.6610\nEpoch 313/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.2530 - binary_accuracy: 0.6600\nEpoch 314/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2527 - binary_accuracy: 0.6595\nEpoch 315/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2528 - binary_accuracy: 0.6590\nEpoch 316/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2527 - binary_accuracy: 0.6605\nEpoch 317/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2527 - binary_accuracy: 0.6587\nEpoch 318/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2525 - binary_accuracy: 0.6602\nEpoch 319/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2521 - binary_accuracy: 0.6602\nEpoch 320/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2519 - binary_accuracy: 0.6590\nEpoch 321/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2521 - binary_accuracy: 0.6600\nEpoch 322/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2519 - binary_accuracy: 0.6587\nEpoch 323/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2513 - binary_accuracy: 0.6579\nEpoch 324/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2509 - binary_accuracy: 0.6597\nEpoch 325/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2513 - binary_accuracy: 0.6602\nEpoch 326/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2508 - binary_accuracy: 0.6577\nEpoch 327/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2505 - binary_accuracy: 0.6572\nEpoch 328/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2503 - binary_accuracy: 0.6584\nEpoch 329/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2505 - binary_accuracy: 0.6561\nEpoch 330/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2502 - binary_accuracy: 0.6572\nEpoch 331/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2502 - binary_accuracy: 0.6569\nEpoch 332/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2500 - binary_accuracy: 0.6595\nEpoch 333/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2501 - binary_accuracy: 0.6561\nEpoch 334/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2499 - binary_accuracy: 0.6569\nEpoch 335/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2498 - binary_accuracy: 0.6556\nEpoch 336/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2494 - binary_accuracy: 0.6572\nEpoch 337/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2496 - binary_accuracy: 0.6572\nEpoch 338/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2495 - binary_accuracy: 0.6546\nEpoch 339/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2493 - binary_accuracy: 0.6523\nEpoch 340/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2494 - binary_accuracy: 0.6554\nEpoch 341/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2493 - binary_accuracy: 0.6543\nEpoch 342/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2489 - binary_accuracy: 0.6512\nEpoch 343/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2491 - binary_accuracy: 0.6541\nEpoch 344/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2492 - binary_accuracy: 0.6530\nEpoch 345/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2486 - binary_accuracy: 0.6546\nEpoch 346/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2485 - binary_accuracy: 0.6528\nEpoch 347/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2484 - binary_accuracy: 0.6528\nEpoch 348/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2485 - binary_accuracy: 0.6538\nEpoch 349/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2480 - binary_accuracy: 0.6520\nEpoch 350/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2485 - binary_accuracy: 0.6538\nEpoch 351/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2483 - binary_accuracy: 0.6489\nEpoch 352/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2479 - binary_accuracy: 0.6520\nEpoch 353/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2480 - binary_accuracy: 0.6525\nEpoch 354/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2480 - binary_accuracy: 0.6515\nEpoch 355/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2476 - binary_accuracy: 0.6536\nEpoch 356/500\n3891/3891 [==============================] - 0s 31us/step - loss: 0.2473 - binary_accuracy: 0.6528\nEpoch 357/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2477 - binary_accuracy: 0.6546\nEpoch 358/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2477 - binary_accuracy: 0.6525\nEpoch 359/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2475 - binary_accuracy: 0.6528\nEpoch 360/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2474 - binary_accuracy: 0.6515\nEpoch 361/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2480 - binary_accuracy: 0.6489\nEpoch 362/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 18us/step - loss: 0.2475 - binary_accuracy: 0.6497\nEpoch 363/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2476 - binary_accuracy: 0.6500\nEpoch 364/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2471 - binary_accuracy: 0.6497\nEpoch 365/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2470 - binary_accuracy: 0.6525\nEpoch 366/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2470 - binary_accuracy: 0.6507\nEpoch 367/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2463 - binary_accuracy: 0.6515\nEpoch 368/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2466 - binary_accuracy: 0.6484\nEpoch 369/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2468 - binary_accuracy: 0.6464\nEpoch 370/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2467 - binary_accuracy: 0.6528\nEpoch 371/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2470 - binary_accuracy: 0.6497\nEpoch 372/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2466 - binary_accuracy: 0.6525\nEpoch 373/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2470 - binary_accuracy: 0.6453\nEpoch 374/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2462 - binary_accuracy: 0.6474\nEpoch 375/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2470 - binary_accuracy: 0.6466\nEpoch 376/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2458 - binary_accuracy: 0.6469\nEpoch 377/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2460 - binary_accuracy: 0.6515\nEpoch 378/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2458 - binary_accuracy: 0.6482\nEpoch 379/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2460 - binary_accuracy: 0.6471\nEpoch 380/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2461 - binary_accuracy: 0.6474\nEpoch 381/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2459 - binary_accuracy: 0.6482\nEpoch 382/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2455 - binary_accuracy: 0.6471\nEpoch 383/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2450 - binary_accuracy: 0.6482\nEpoch 384/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2454 - binary_accuracy: 0.6479\nEpoch 385/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2459 - binary_accuracy: 0.6446\nEpoch 386/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2456 - binary_accuracy: 0.6479\nEpoch 387/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2452 - binary_accuracy: 0.6461\nEpoch 388/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2447 - binary_accuracy: 0.6471\nEpoch 389/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2454 - binary_accuracy: 0.6453\nEpoch 390/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2452 - binary_accuracy: 0.6466\nEpoch 391/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2457 - binary_accuracy: 0.6474\nEpoch 392/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2448 - binary_accuracy: 0.6466\nEpoch 393/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2443 - binary_accuracy: 0.6441\nEpoch 394/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2445 - binary_accuracy: 0.6500\nEpoch 395/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2447 - binary_accuracy: 0.6479\nEpoch 396/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2444 - binary_accuracy: 0.6453\nEpoch 397/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2448 - binary_accuracy: 0.6435\nEpoch 398/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2453 - binary_accuracy: 0.6417\nEpoch 399/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2441 - binary_accuracy: 0.6441\nEpoch 400/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2443 - binary_accuracy: 0.6438\nEpoch 401/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2446 - binary_accuracy: 0.6412\nEpoch 402/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2439 - binary_accuracy: 0.6443\nEpoch 403/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2442 - binary_accuracy: 0.6446\nEpoch 404/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2436 - binary_accuracy: 0.6425\nEpoch 405/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2435 - binary_accuracy: 0.6425\nEpoch 406/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2440 - binary_accuracy: 0.6381\nEpoch 407/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2446 - binary_accuracy: 0.6443\nEpoch 408/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2435 - binary_accuracy: 0.6433\nEpoch 409/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2432 - binary_accuracy: 0.6433\nEpoch 410/500\n3891/3891 [==============================] - 0s 16us/step - loss: 0.2439 - binary_accuracy: 0.6420\nEpoch 411/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2434 - binary_accuracy: 0.6430\nEpoch 412/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2433 - binary_accuracy: 0.6417\nEpoch 413/500\n3891/3891 [==============================] - ETA: 0s - loss: 0.2363 - binary_accuracy: 0.645 - 0s 21us/step - loss: 0.2433 - binary_accuracy: 0.6443\nEpoch 414/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2441 - binary_accuracy: 0.6405\nEpoch 415/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2434 - binary_accuracy: 0.6402\nEpoch 416/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2429 - binary_accuracy: 0.6446\nEpoch 417/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2429 - binary_accuracy: 0.6405\nEpoch 418/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2427 - binary_accuracy: 0.6394\nEpoch 419/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2427 - binary_accuracy: 0.6402\nEpoch 420/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2425 - binary_accuracy: 0.6405\nEpoch 421/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2418 - binary_accuracy: 0.6389\nEpoch 422/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2427 - binary_accuracy: 0.6407\nEpoch 423/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2434 - binary_accuracy: 0.6420\nEpoch 424/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2434 - binary_accuracy: 0.6371\nEpoch 425/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2422 - binary_accuracy: 0.6412\nEpoch 426/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2430 - binary_accuracy: 0.6410\nEpoch 427/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2420 - binary_accuracy: 0.6392\nEpoch 428/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2418 - binary_accuracy: 0.6387\nEpoch 429/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2419 - binary_accuracy: 0.6425\nEpoch 430/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2421 - binary_accuracy: 0.6402\nEpoch 431/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2414 - binary_accuracy: 0.6384\nEpoch 432/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2418 - binary_accuracy: 0.6384\nEpoch 433/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2419 - binary_accuracy: 0.6405\nEpoch 434/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 22us/step - loss: 0.2410 - binary_accuracy: 0.6430\nEpoch 435/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2409 - binary_accuracy: 0.6423\nEpoch 436/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2412 - binary_accuracy: 0.6423\nEpoch 437/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2408 - binary_accuracy: 0.6410\nEpoch 438/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2409 - binary_accuracy: 0.6381\nEpoch 439/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2408 - binary_accuracy: 0.6361\nEpoch 440/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2413 - binary_accuracy: 0.6402\nEpoch 441/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2408 - binary_accuracy: 0.6412\nEpoch 442/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2411 - binary_accuracy: 0.6376\nEpoch 443/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2410 - binary_accuracy: 0.6384\nEpoch 444/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2418 - binary_accuracy: 0.6387\nEpoch 445/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2409 - binary_accuracy: 0.6369\nEpoch 446/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2404 - binary_accuracy: 0.6379\nEpoch 447/500\n3891/3891 [==============================] - 0s 32us/step - loss: 0.2401 - binary_accuracy: 0.6397\nEpoch 448/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2412 - binary_accuracy: 0.6369\nEpoch 449/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2423 - binary_accuracy: 0.6361\nEpoch 450/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2415 - binary_accuracy: 0.6392\nEpoch 451/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2396 - binary_accuracy: 0.6405\nEpoch 452/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2399 - binary_accuracy: 0.6384\nEpoch 453/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2408 - binary_accuracy: 0.6376\nEpoch 454/500\n3891/3891 [==============================] - 0s 27us/step - loss: 0.2393 - binary_accuracy: 0.6392\nEpoch 455/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2400 - binary_accuracy: 0.6389\nEpoch 456/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.2399 - binary_accuracy: 0.6376\nEpoch 457/500\n3891/3891 [==============================] - 0s 26us/step - loss: 0.2395 - binary_accuracy: 0.6376\nEpoch 458/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2387 - binary_accuracy: 0.6381\nEpoch 459/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2394 - binary_accuracy: 0.6371\nEpoch 460/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2389 - binary_accuracy: 0.6381\nEpoch 461/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2384 - binary_accuracy: 0.6363\nEpoch 462/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2396 - binary_accuracy: 0.6345\nEpoch 463/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2394 - binary_accuracy: 0.6379\nEpoch 464/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2378 - binary_accuracy: 0.6384\nEpoch 465/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2378 - binary_accuracy: 0.6371\nEpoch 466/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2382 - binary_accuracy: 0.6387\nEpoch 467/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2380 - binary_accuracy: 0.6356\nEpoch 468/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2374 - binary_accuracy: 0.6394\nEpoch 469/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2382 - binary_accuracy: 0.6312\nEpoch 470/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2389 - binary_accuracy: 0.6376\nEpoch 471/500\n3891/3891 [==============================] - 0s 17us/step - loss: 0.2366 - binary_accuracy: 0.6394\nEpoch 472/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2370 - binary_accuracy: 0.6381\nEpoch 473/500\n3891/3891 [==============================] - 0s 22us/step - loss: 0.2379 - binary_accuracy: 0.6389\nEpoch 474/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2378 - binary_accuracy: 0.6415\nEpoch 475/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2372 - binary_accuracy: 0.6369\nEpoch 476/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2373 - binary_accuracy: 0.6371\nEpoch 477/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2362 - binary_accuracy: 0.6345\nEpoch 478/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2370 - binary_accuracy: 0.6410\nEpoch 479/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2361 - binary_accuracy: 0.6379\nEpoch 480/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2359 - binary_accuracy: 0.6381\nEpoch 481/500\n3891/3891 [==============================] - 0s 29us/step - loss: 0.2368 - binary_accuracy: 0.6343\nEpoch 482/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2359 - binary_accuracy: 0.6376\nEpoch 483/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2356 - binary_accuracy: 0.6369\nEpoch 484/500\n3891/3891 [==============================] - 0s 18us/step - loss: 0.2378 - binary_accuracy: 0.6366\nEpoch 485/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2364 - binary_accuracy: 0.6389\nEpoch 486/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2357 - binary_accuracy: 0.6389\nEpoch 487/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2363 - binary_accuracy: 0.6371\nEpoch 488/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2371 - binary_accuracy: 0.6369\nEpoch 489/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2366 - binary_accuracy: 0.6320\nEpoch 490/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2359 - binary_accuracy: 0.6389\nEpoch 491/500\n3891/3891 [==============================] - 0s 28us/step - loss: 0.2368 - binary_accuracy: 0.6366\nEpoch 492/500\n3891/3891 [==============================] - 0s 23us/step - loss: 0.2359 - binary_accuracy: 0.6361\nEpoch 493/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2378 - binary_accuracy: 0.6348\nEpoch 494/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2361 - binary_accuracy: 0.6369\nEpoch 495/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2367 - binary_accuracy: 0.6340\nEpoch 496/500\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2359 - binary_accuracy: 0.6389\nEpoch 497/500\n3891/3891 [==============================] - 0s 25us/step - loss: 0.2352 - binary_accuracy: 0.6351\nEpoch 498/500\n3891/3891 [==============================] - 0s 24us/step - loss: 0.2353 - binary_accuracy: 0.6376\nEpoch 499/500\n3891/3891 [==============================] - 0s 20us/step - loss: 0.2357 - binary_accuracy: 0.6384\nEpoch 500/500\n3891/3891 [==============================] - 0s 21us/step - loss: 0.2361 - binary_accuracy: 0.6348\n*ding*... Testing Accuracy on test set\n0.6834532374100719\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c0980c64f2a6110235e0e65e6f715d4810cf9d06"
      },
      "cell_type": "markdown",
      "source": "## Make the prediction ##"
    },
    {
      "metadata": {
        "_cell_guid": "9ed01b17-e2e8-4a24-8c9e-9c9db9019c6e",
        "_uuid": "f4461c5176b3f6840e3941c1233bf5ff77d04abe",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def format_dataset(df_sample):\n    df_pred = pd.DataFrame()\n    df_pred['Season'], df_pred['WTeamID'], df_pred['LTeamID'] = df_sample_sub['ID'].str.split('_', 2).str\n    df_pred = df_pred.astype(int) #DO I NEED THIS?\n    df_winseeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\n    df_lossseeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\n    df_preddummy = pd.merge(left=df_pred, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\n    df_predmerge = pd.merge(left=df_preddummy, right=df_lossseeds, on=['Season', 'LTeamID'])\n    df_predmerge = df_predmerge.fillna(17)\n    df_predmerge['SeedDiff'] = df_predmerge.WSeed - df_predmerge.LSeed\n    df_predmerge = df_predmerge.rename(columns={'Season':'Year'})\n    df_predictions = df_predmerge[['WTeamID','LTeamID','SeedDiff']] # We really should add year to this somewhere\n    df_predictions['WTeamID'] = df_predictions['WTeamID'].astype(str)\n    df_predictions['LTeamID'] = df_predictions['LTeamID'].astype(str)\n    for x in df_predictions.columns:\n        df_predictions[x]=df_predictions[x].astype(df_preenc[x].dtypes.name)\n    return df_predictions.iloc[:, 0:3].values\n\n\n\n#Convert the prediction table to our format\ndf_predX = format_dataset(pd.read_csv(data_dir + 'SampleSubmissionStage1.csv'))\n#Encode the Predictions\ndf_predX[:, 0] = enc_1.transform(df_predX[:, 0])\ndf_predX[:, 1] = enc_2.transform(df_predX[:, 1])\ndf_predX = onehotencoder.transform(df_predX).toarray()\ndf_predX = sc.transform(df_predX)\n#Generate the predictions and save\ny_p = classifier.predict(df_predX)\nclipped_preds = np.clip(y_p, 0.0001, 0.999)\ndf_out=df_sample_sub\ndf_out.Pred = clipped_preds\ndf_out.to_csv('out.csv', index=False)\ndisplay(df_out)\nprint(df_out['Pred'].std())\n",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  app.launch_new_instance()\n",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                  ID      Pred\n0     2014_1107_1110  0.005108\n1     2014_1107_1112  0.005108\n2     2014_1107_1113  0.005108\n3     2014_1107_1124  0.005108\n4     2014_1107_1140  0.005108\n5     2014_1107_1142  0.454111\n6     2014_1107_1153  0.005108\n7     2014_1107_1157  0.005108\n8     2014_1107_1160  0.999000\n9     2014_1107_1163  0.000100\n10    2014_1107_1166  0.005108\n11    2014_1107_1173  0.005108\n12    2014_1107_1174  0.999000\n13    2014_1107_1181  0.255895\n14    2014_1107_1184  0.999000\n15    2014_1107_1196  0.005108\n16    2014_1107_1203  0.253184\n17    2014_1107_1211  0.999000\n18    2014_1107_1217  0.999000\n19    2014_1107_1234  0.999000\n20    2014_1107_1235  0.999000\n21    2014_1107_1242  0.005108\n22    2014_1107_1243  0.095885\n23    2014_1107_1246  0.999000\n24    2014_1107_1257  0.999000\n25    2014_1107_1264  0.243302\n26    2014_1107_1269  0.843911\n27    2014_1107_1272  0.005108\n28    2014_1107_1273  0.365992\n29    2014_1107_1276  0.475471\n...              ...       ...\n9082  2017_1437_1458  0.337854\n9083  2017_1437_1462  0.498706\n9084  2017_1438_1439  0.005108\n9085  2017_1438_1448  0.005108\n9086  2017_1438_1452  0.005108\n9087  2017_1438_1455  0.479534\n9088  2017_1438_1457  0.537392\n9089  2017_1438_1458  0.999000\n9090  2017_1438_1462  0.005108\n9091  2017_1439_1448  0.604954\n9092  2017_1439_1452  0.005108\n9093  2017_1439_1455  0.999000\n9094  2017_1439_1457  0.999000\n9095  2017_1439_1458  0.005108\n9096  2017_1439_1462  0.005108\n9097  2017_1448_1452  0.005108\n9098  2017_1448_1455  0.072023\n9099  2017_1448_1457  0.005108\n9100  2017_1448_1458  0.402701\n9101  2017_1448_1462  0.802828\n9102  2017_1452_1455  0.018158\n9103  2017_1452_1457  0.005108\n9104  2017_1452_1458  0.999000\n9105  2017_1452_1462  0.999000\n9106  2017_1455_1457  0.876236\n9107  2017_1455_1458  0.050939\n9108  2017_1455_1462  0.245645\n9109  2017_1457_1458  0.881264\n9110  2017_1457_1462  0.005108\n9111  2017_1458_1462  0.999000\n\n[9112 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014_1107_1110</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014_1107_1112</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014_1107_1113</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014_1107_1124</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014_1107_1140</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2014_1107_1142</td>\n      <td>0.454111</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2014_1107_1153</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2014_1107_1157</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2014_1107_1160</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2014_1107_1163</td>\n      <td>0.000100</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2014_1107_1166</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2014_1107_1173</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2014_1107_1174</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2014_1107_1181</td>\n      <td>0.255895</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2014_1107_1184</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2014_1107_1196</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2014_1107_1203</td>\n      <td>0.253184</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2014_1107_1211</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2014_1107_1217</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2014_1107_1234</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2014_1107_1235</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2014_1107_1242</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2014_1107_1243</td>\n      <td>0.095885</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2014_1107_1246</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2014_1107_1257</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2014_1107_1264</td>\n      <td>0.243302</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2014_1107_1269</td>\n      <td>0.843911</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2014_1107_1272</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2014_1107_1273</td>\n      <td>0.365992</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2014_1107_1276</td>\n      <td>0.475471</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9082</th>\n      <td>2017_1437_1458</td>\n      <td>0.337854</td>\n    </tr>\n    <tr>\n      <th>9083</th>\n      <td>2017_1437_1462</td>\n      <td>0.498706</td>\n    </tr>\n    <tr>\n      <th>9084</th>\n      <td>2017_1438_1439</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9085</th>\n      <td>2017_1438_1448</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9086</th>\n      <td>2017_1438_1452</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9087</th>\n      <td>2017_1438_1455</td>\n      <td>0.479534</td>\n    </tr>\n    <tr>\n      <th>9088</th>\n      <td>2017_1438_1457</td>\n      <td>0.537392</td>\n    </tr>\n    <tr>\n      <th>9089</th>\n      <td>2017_1438_1458</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>9090</th>\n      <td>2017_1438_1462</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9091</th>\n      <td>2017_1439_1448</td>\n      <td>0.604954</td>\n    </tr>\n    <tr>\n      <th>9092</th>\n      <td>2017_1439_1452</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9093</th>\n      <td>2017_1439_1455</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>9094</th>\n      <td>2017_1439_1457</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>9095</th>\n      <td>2017_1439_1458</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9096</th>\n      <td>2017_1439_1462</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9097</th>\n      <td>2017_1448_1452</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9098</th>\n      <td>2017_1448_1455</td>\n      <td>0.072023</td>\n    </tr>\n    <tr>\n      <th>9099</th>\n      <td>2017_1448_1457</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9100</th>\n      <td>2017_1448_1458</td>\n      <td>0.402701</td>\n    </tr>\n    <tr>\n      <th>9101</th>\n      <td>2017_1448_1462</td>\n      <td>0.802828</td>\n    </tr>\n    <tr>\n      <th>9102</th>\n      <td>2017_1452_1455</td>\n      <td>0.018158</td>\n    </tr>\n    <tr>\n      <th>9103</th>\n      <td>2017_1452_1457</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9104</th>\n      <td>2017_1452_1458</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>9105</th>\n      <td>2017_1452_1462</td>\n      <td>0.999000</td>\n    </tr>\n    <tr>\n      <th>9106</th>\n      <td>2017_1455_1457</td>\n      <td>0.876236</td>\n    </tr>\n    <tr>\n      <th>9107</th>\n      <td>2017_1455_1458</td>\n      <td>0.050939</td>\n    </tr>\n    <tr>\n      <th>9108</th>\n      <td>2017_1455_1462</td>\n      <td>0.245645</td>\n    </tr>\n    <tr>\n      <th>9109</th>\n      <td>2017_1457_1458</td>\n      <td>0.881264</td>\n    </tr>\n    <tr>\n      <th>9110</th>\n      <td>2017_1457_1462</td>\n      <td>0.005108</td>\n    </tr>\n    <tr>\n      <th>9111</th>\n      <td>2017_1458_1462</td>\n      <td>0.999000</td>\n    </tr>\n  </tbody>\n</table>\n<p>9112 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": "0.4399929344654083\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8967b3ce7c1031938f143faf99031338f6d76f09"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}