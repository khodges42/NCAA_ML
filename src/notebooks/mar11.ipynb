{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "d70f47ef-8793-40f0-a24a-73531e2c8a85",
        "_uuid": "9853586a0dc75ce39e7c7ffcde1eb4d47c6fb02e"
      },
      "cell_type": "markdown",
      "source": "## Overview ##\n\nBased on Starter Kernel [Logistic Regression on Tournament Seeds by Kasper P. Lauritzen](https://www.kaggle.com/kplauritzen/notebookde27b18258?scriptVersionId=804590) "
    },
    {
      "metadata": {
        "_cell_guid": "0c233e05-c63d-4866-96dc-bb38d444bf84",
        "_uuid": "5464dc4b196dc4c8dd0323bbd71b75724113e2af",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import GridSearchCV\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom subprocess import check_output\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\n\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "05f13f0b-e969-45a5-a05b-694cb388a056",
        "_uuid": "819472385a23f3fd5aaf4172b4f8db227cf5271f"
      },
      "cell_type": "markdown",
      "source": "## Load the training data ##\nWe're keeping it simple & using only 2 files for this model: the Tourney seeds & Compact results."
    },
    {
      "metadata": {
        "_cell_guid": "aafa51a3-6f36-4469-8041-6741b275254e",
        "_uuid": "bf8ee168a0372e883332d6bb0ce5c89c13143650",
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_dir = '../input/'\ndf_seeds = pd.read_csv(data_dir + 'NCAATourneySeeds.csv')\n#df_tour = pd.read_csv(data_dir + 'NCAATourneyDetailedResults.csv')\ndf_tour = pd.read_csv(data_dir + 'RegularSeasonCompactResults.csv')\nteams = pd.read_csv(data_dir + 'Teams.csv')\n\ndef seed_to_int(seed):\n    s_int = int(seed[1:3])\n    return s_int\ndf_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\ndf_seeds.drop(labels=['Seed'], inplace=True, axis=1) # This is the string label\ndf_tour.drop(labels=['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], inplace=True, axis=1)\ndf_tour.head()\n",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 133,
          "data": {
            "text/plain": "   Season  WTeamID  LTeamID\n0    1985     1228     1328\n1    1985     1106     1354\n2    1985     1112     1223\n3    1985     1165     1432\n4    1985     1192     1447",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Season</th>\n      <th>WTeamID</th>\n      <th>LTeamID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1985</td>\n      <td>1228</td>\n      <td>1328</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1985</td>\n      <td>1106</td>\n      <td>1354</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1985</td>\n      <td>1112</td>\n      <td>1223</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1985</td>\n      <td>1165</td>\n      <td>1432</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1985</td>\n      <td>1192</td>\n      <td>1447</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ebb26984-709f-4f62-925e-16b2ea1226d2",
        "_uuid": "da8de9fda8a9e8d7bd7cea13c83a1139ade69a2f"
      },
      "cell_type": "markdown",
      "source": "Build out the id string (year_wteam_lteam)\nCreate a prediction at the end."
    },
    {
      "metadata": {
        "_cell_guid": "3b727e85-b452-4d27-a197-d437499f6a5c",
        "_kg_hide-output": false,
        "_uuid": "a6f3a5658dbe11d62526d90bfaaa8f5b23dea2bd",
        "_kg_hide-input": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_winseeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\ndf_lossseeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\ndf_dummy = pd.merge(left=df_tour, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\ndf_concat = pd.merge(left=df_dummy, right=df_lossseeds, on=['Season', 'LTeamID'])\ndf_true=df_concat.copy()\n\ncolumnsTitles=[\"LTeamID\",\"WTeamID\"]\ndf_false = df_concat.rename(columns={'WTeamID': 'LTeamID_', 'LTeamID': 'WTeamID_'}) #idk if i have to do this I just didnt want to create issues\ndf_false = df_false.rename(columns={'LTeamID_': 'LTeamID', 'WTeamID_': 'WTeamID'})\ndf_false = df_false.rename(columns={'WSeed': 'LSeed_', 'LSeed': 'WSeed_'}) #idk if i have to do this I just didnt want to create issues\ndf_false = df_false.rename(columns={'LSeed_': 'LSeed', 'WSeed_': 'WSeed'})\n\n\ndf_true['label'] = 1\ndf_false['label'] = 0\n\ndf = df_true.append(df_false, ignore_index=True)\ndf = df.fillna(17)\n\n#df['WTID']=df.apply(build_wteamyear, axis=1) #again, probably better way to do this and save a function\n#df['LTID']=df.apply(build_lteamyear, axis=1)\ndf['SeedDiff'] =  df.WSeed - df.LSeed #Lower seeds are better, so Negative means that the lower seed team won.\ndf = df[df['Season'] > 2013] # We want to train on 2014 and above.\n\ndf = df[['WTeamID', 'LTeamID', 'SeedDiff', 'label']]\ndf.head()\n\n",
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 159,
          "data": {
            "text/plain": "       WTeamID  LTeamID  SeedDiff  label\n15289     1103     1157       1.0      1\n15290     1279     1157       1.0      1\n15291     1278     1157       1.0      1\n15292     1418     1157      -2.0      1\n15293     1155     1157       1.0      1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WTeamID</th>\n      <th>LTeamID</th>\n      <th>SeedDiff</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15289</th>\n      <td>1103</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15290</th>\n      <td>1279</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15291</th>\n      <td>1278</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15292</th>\n      <td>1418</td>\n      <td>1157</td>\n      <td>-2.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15293</th>\n      <td>1155</td>\n      <td>1157</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c8fd85d7-782a-4370-ba22-61b53fa9fe8a",
        "_uuid": "0d146d07c99b9b4fdcde96e7fe3aff1d8382d8cd"
      },
      "cell_type": "markdown",
      "source": "## Encode and, Scale and Split ##"
    },
    {
      "metadata": {
        "_cell_guid": "14d21c09-afdc-4c8a-ad6e-ac7ccf216c3d",
        "_uuid": "1a9c7352e5baa2fb64c528503d58ddcd8ab5004c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "X = df.iloc[:, 0:3].values\ny = df.iloc[:, 3].values\n\n\nenc_1 = LabelEncoder()\nX[:, 0] = enc_1.fit_transform(X[:, 0])\nenc_2 = LabelEncoder()\nX[:, 1] = enc_2.fit_transform(X[:, 1])\nonehotencoder = OneHotEncoder(categorical_features = [0,1],handle_unknown='error') #handle_unknown='unknown'or impute\nX = onehotencoder.fit_transform(X).toarray()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nds_width=X_test.shape[1]\n",
      "execution_count": 160,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "595df905-c0af-4cd9-88f2-1f7f7b68dee2",
        "_uuid": "25cfee848688706e19c91fbc45bce80338b4be85"
      },
      "cell_type": "markdown",
      "source": "## Build the classifier and hit the button ##"
    },
    {
      "metadata": {
        "_cell_guid": "ea1b2af7-d688-42d7-91a3-0e6414e4c701",
        "_uuid": "847d46c9b67f30410852520d0afe5b1cb0b6b72a",
        "scrolled": false,
        "trusted": true,
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "from keras.layers import LeakyReLU\nfrom keras import metrics\nfrom keras import optimizers\n\n# 61%  //Dense(6, he_normal)//leakyrelu alpha 0.2//Dense(16, he_normal)\n# leakyrelu alpha 0.2//Dense(16, he_normal)//leakyrelu alpha 0.2//Dense(1, he_normal, sigmoid)//SGD, Mean_Squared_Error\n# Third Attempt.\nclassifier = Sequential()\nclassifier.add(Dense(13,input_shape=(ds_width,),kernel_initializer = 'normal',activation='relu'))\n#classifier.add(LeakyReLU(alpha=0.2))\nclassifier.add(Dense(6, activation='relu',kernel_initializer = 'normal',))\n#classifier.add(LeakyReLU(alpha=0.2))\n#classifier.add(Dense(64, activation='relu',kernel_initializer = 'normal',))\nclassifier.add(Dense(1,kernel_initializer = 'normal' ))\nclassifier.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['binary_accuracy']) #binary_crossentropy\nprint(\"Cooking... Please wait\")\nclassifier.fit(X_train, y_train, batch_size = 250, epochs = 200, verbose=1)\nprint(\"*ding*... Testing Accuracy on test set\")\n#Run Predictions on the test set\npred_test = classifier.predict(X_test)\n\npred_test = (pred_test > 0.5)\ncm = confusion_matrix(pred_test, y_test)\nprint ((cm[0][0]+cm[1][1])/(sum(cm[0])+sum(cm[1])))",
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Cooking... Please wait\nEpoch 1/200\n3891/3891 [==============================] - 3s 880us/step - loss: 0.4698 - binary_accuracy: 0.5009\nEpoch 2/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.4061 - binary_accuracy: 0.5009\nEpoch 3/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.3108 - binary_accuracy: 0.5163\nEpoch 4/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.2155 - binary_accuracy: 0.6279\nEpoch 5/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.1823 - binary_accuracy: 0.7137\nEpoch 6/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1690 - binary_accuracy: 0.7422\nEpoch 7/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.1601 - binary_accuracy: 0.7538\nEpoch 8/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.1539 - binary_accuracy: 0.7646\nEpoch 9/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.1494 - binary_accuracy: 0.7723\nEpoch 10/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.1459 - binary_accuracy: 0.7813\nEpoch 11/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.1430 - binary_accuracy: 0.7841\nEpoch 12/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.1405 - binary_accuracy: 0.7851\nEpoch 13/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.1384 - binary_accuracy: 0.7913\nEpoch 14/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.1363 - binary_accuracy: 0.7939\nEpoch 15/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.1343 - binary_accuracy: 0.8006\nEpoch 16/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.1327 - binary_accuracy: 0.8024\nEpoch 17/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1308 - binary_accuracy: 0.8070\nEpoch 18/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.1292 - binary_accuracy: 0.8088\nEpoch 19/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.1274 - binary_accuracy: 0.8144\nEpoch 20/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.1260 - binary_accuracy: 0.8160\nEpoch 21/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.1243 - binary_accuracy: 0.8214\nEpoch 22/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1229 - binary_accuracy: 0.8227\nEpoch 23/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.1214 - binary_accuracy: 0.8250\nEpoch 24/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.1199 - binary_accuracy: 0.8260\nEpoch 25/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.1186 - binary_accuracy: 0.8288\nEpoch 26/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.1170 - binary_accuracy: 0.8283\nEpoch 27/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.1158 - binary_accuracy: 0.8360\nEpoch 28/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.1146 - binary_accuracy: 0.8355\nEpoch 29/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.1134 - binary_accuracy: 0.8383\nEpoch 30/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.1122 - binary_accuracy: 0.8414\nEpoch 31/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1113 - binary_accuracy: 0.8437\nEpoch 32/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.1101 - binary_accuracy: 0.8430\nEpoch 33/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.1091 - binary_accuracy: 0.8461\nEpoch 34/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.1082 - binary_accuracy: 0.8481\nEpoch 35/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1072 - binary_accuracy: 0.8494\nEpoch 36/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1062 - binary_accuracy: 0.8507\nEpoch 37/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.1057 - binary_accuracy: 0.8489\nEpoch 38/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.1045 - binary_accuracy: 0.8517\nEpoch 39/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.1037 - binary_accuracy: 0.8543\nEpoch 40/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.1028 - binary_accuracy: 0.8538\nEpoch 41/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1020 - binary_accuracy: 0.8512\nEpoch 42/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.1010 - binary_accuracy: 0.8548\nEpoch 43/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.1005 - binary_accuracy: 0.8592\nEpoch 44/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0999 - binary_accuracy: 0.8615\nEpoch 45/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0995 - binary_accuracy: 0.8592\nEpoch 46/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0988 - binary_accuracy: 0.8615\nEpoch 47/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0981 - binary_accuracy: 0.8628\nEpoch 48/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0973 - binary_accuracy: 0.8622\nEpoch 49/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0968 - binary_accuracy: 0.8643\nEpoch 50/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0963 - binary_accuracy: 0.8651\nEpoch 51/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0959 - binary_accuracy: 0.8653\nEpoch 52/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.0956 - binary_accuracy: 0.8689\nEpoch 53/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0949 - binary_accuracy: 0.8658\nEpoch 54/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0949 - binary_accuracy: 0.8700: 0s - loss: 0.0946 - binary_accuracy: 0.871\nEpoch 55/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0938 - binary_accuracy: 0.8700\nEpoch 56/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0936 - binary_accuracy: 0.8702\nEpoch 57/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0932 - binary_accuracy: 0.8694\nEpoch 58/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0928 - binary_accuracy: 0.8682\nEpoch 59/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0927 - binary_accuracy: 0.8700\nEpoch 60/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0921 - binary_accuracy: 0.8702\nEpoch 61/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0915 - binary_accuracy: 0.8728\nEpoch 62/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0915 - binary_accuracy: 0.8712\nEpoch 63/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0910 - binary_accuracy: 0.8718\nEpoch 64/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0912 - binary_accuracy: 0.8702\nEpoch 65/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0904 - binary_accuracy: 0.8733\nEpoch 66/200\n3891/3891 [==============================] - 0s 26us/step - loss: 0.0901 - binary_accuracy: 0.8712\nEpoch 67/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0898 - binary_accuracy: 0.8730\nEpoch 68/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0892 - binary_accuracy: 0.8746\nEpoch 69/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0889 - binary_accuracy: 0.8720\nEpoch 70/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0887 - binary_accuracy: 0.8718\nEpoch 71/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0886 - binary_accuracy: 0.8741\nEpoch 72/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0883 - binary_accuracy: 0.8723\nEpoch 73/200\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 25us/step - loss: 0.0877 - binary_accuracy: 0.8746\nEpoch 74/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0876 - binary_accuracy: 0.8743\nEpoch 75/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0869 - binary_accuracy: 0.8736\nEpoch 76/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0867 - binary_accuracy: 0.8774\nEpoch 77/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0865 - binary_accuracy: 0.8733\nEpoch 78/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0863 - binary_accuracy: 0.8774\nEpoch 79/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0866 - binary_accuracy: 0.8754\nEpoch 80/200\n3891/3891 [==============================] - 0s 26us/step - loss: 0.0860 - binary_accuracy: 0.8766\nEpoch 81/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0855 - binary_accuracy: 0.8782\nEpoch 82/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0854 - binary_accuracy: 0.8769\nEpoch 83/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0850 - binary_accuracy: 0.8774\nEpoch 84/200\n3891/3891 [==============================] - 0s 27us/step - loss: 0.0853 - binary_accuracy: 0.8751\nEpoch 85/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0850 - binary_accuracy: 0.8769\nEpoch 86/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0851 - binary_accuracy: 0.8800\nEpoch 87/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0852 - binary_accuracy: 0.8779\nEpoch 88/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0842 - binary_accuracy: 0.8790\nEpoch 89/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.0843 - binary_accuracy: 0.8782\nEpoch 90/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0843 - binary_accuracy: 0.8754\nEpoch 91/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0838 - binary_accuracy: 0.8787: 0s - loss: 0.0849 - binary_accuracy: 0.878\nEpoch 92/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0836 - binary_accuracy: 0.8787\nEpoch 93/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0838 - binary_accuracy: 0.8797\nEpoch 94/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0835 - binary_accuracy: 0.8774\nEpoch 95/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0836 - binary_accuracy: 0.8795\nEpoch 96/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0832 - binary_accuracy: 0.8761\nEpoch 97/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0828 - binary_accuracy: 0.8772\nEpoch 98/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0826 - binary_accuracy: 0.8779\nEpoch 99/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0821 - binary_accuracy: 0.8813\nEpoch 100/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0823 - binary_accuracy: 0.8779\nEpoch 101/200\n3891/3891 [==============================] - 0s 26us/step - loss: 0.0819 - binary_accuracy: 0.8774\nEpoch 102/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0818 - binary_accuracy: 0.8797\nEpoch 103/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0816 - binary_accuracy: 0.8787\nEpoch 104/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0814 - binary_accuracy: 0.8802\nEpoch 105/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0814 - binary_accuracy: 0.8795\nEpoch 106/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0814 - binary_accuracy: 0.8779\nEpoch 107/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0814 - binary_accuracy: 0.8802\nEpoch 108/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0821 - binary_accuracy: 0.8779\nEpoch 109/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0811 - binary_accuracy: 0.8823\nEpoch 110/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0811 - binary_accuracy: 0.8805\nEpoch 111/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0805 - binary_accuracy: 0.8813\nEpoch 112/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0805 - binary_accuracy: 0.8825\nEpoch 113/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0805 - binary_accuracy: 0.8797\nEpoch 114/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0803 - binary_accuracy: 0.8828\nEpoch 115/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0801 - binary_accuracy: 0.8808\nEpoch 116/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0800 - binary_accuracy: 0.8823\nEpoch 117/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0801 - binary_accuracy: 0.8808\nEpoch 118/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0796 - binary_accuracy: 0.8810\nEpoch 119/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0797 - binary_accuracy: 0.8820\nEpoch 120/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.0795 - binary_accuracy: 0.8813\nEpoch 121/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0797 - binary_accuracy: 0.8823\nEpoch 122/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0796 - binary_accuracy: 0.8859\nEpoch 123/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0792 - binary_accuracy: 0.8849\nEpoch 124/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0791 - binary_accuracy: 0.8836\nEpoch 125/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0787 - binary_accuracy: 0.8828\nEpoch 126/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0785 - binary_accuracy: 0.8823\nEpoch 127/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0788 - binary_accuracy: 0.8831\nEpoch 128/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0786 - binary_accuracy: 0.8836\nEpoch 129/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0787 - binary_accuracy: 0.8795\nEpoch 130/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0782 - binary_accuracy: 0.8843\nEpoch 131/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0784 - binary_accuracy: 0.8833\nEpoch 132/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0788 - binary_accuracy: 0.8810\nEpoch 133/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0787 - binary_accuracy: 0.8843\nEpoch 134/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0782 - binary_accuracy: 0.8838\nEpoch 135/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0779 - binary_accuracy: 0.8864\nEpoch 136/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0777 - binary_accuracy: 0.8808\nEpoch 137/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0790 - binary_accuracy: 0.8838\nEpoch 138/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0781 - binary_accuracy: 0.8805\nEpoch 139/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0778 - binary_accuracy: 0.8874\nEpoch 140/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0778 - binary_accuracy: 0.8838\nEpoch 141/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0776 - binary_accuracy: 0.8849\nEpoch 142/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0775 - binary_accuracy: 0.8818\nEpoch 143/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0772 - binary_accuracy: 0.8864\nEpoch 144/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0774 - binary_accuracy: 0.8846\nEpoch 145/200\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "3891/3891 [==============================] - 0s 22us/step - loss: 0.0766 - binary_accuracy: 0.8846\nEpoch 146/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0774 - binary_accuracy: 0.8828\nEpoch 147/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0770 - binary_accuracy: 0.8838\nEpoch 148/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.0772 - binary_accuracy: 0.8833\nEpoch 149/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0768 - binary_accuracy: 0.8841\nEpoch 150/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0766 - binary_accuracy: 0.8856\nEpoch 151/200\n3891/3891 [==============================] - 0s 27us/step - loss: 0.0770 - binary_accuracy: 0.8872\nEpoch 152/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0764 - binary_accuracy: 0.8869\nEpoch 153/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0766 - binary_accuracy: 0.8861\nEpoch 154/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0766 - binary_accuracy: 0.8856\nEpoch 155/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0767 - binary_accuracy: 0.8846\nEpoch 156/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.0770 - binary_accuracy: 0.8877\nEpoch 157/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0767 - binary_accuracy: 0.8861\nEpoch 158/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0764 - binary_accuracy: 0.8838\nEpoch 159/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0758 - binary_accuracy: 0.8867\nEpoch 160/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0759 - binary_accuracy: 0.8856\nEpoch 161/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0763 - binary_accuracy: 0.8831\nEpoch 162/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0764 - binary_accuracy: 0.8831\nEpoch 163/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0765 - binary_accuracy: 0.8892\nEpoch 164/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0754 - binary_accuracy: 0.8867\nEpoch 165/200\n3891/3891 [==============================] - 0s 29us/step - loss: 0.0756 - binary_accuracy: 0.8885\nEpoch 166/200\n3891/3891 [==============================] - 0s 26us/step - loss: 0.0759 - binary_accuracy: 0.8849\nEpoch 167/200\n3891/3891 [==============================] - 0s 27us/step - loss: 0.0760 - binary_accuracy: 0.8854\nEpoch 168/200\n3891/3891 [==============================] - 0s 28us/step - loss: 0.0755 - binary_accuracy: 0.8864\nEpoch 169/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0750 - binary_accuracy: 0.8879\nEpoch 170/200\n3891/3891 [==============================] - 0s 24us/step - loss: 0.0748 - binary_accuracy: 0.8859\nEpoch 171/200\n3891/3891 [==============================] - 0s 33us/step - loss: 0.0753 - binary_accuracy: 0.8828\nEpoch 172/200\n3891/3891 [==============================] - 0s 30us/step - loss: 0.0751 - binary_accuracy: 0.8856\nEpoch 173/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0750 - binary_accuracy: 0.8885\nEpoch 174/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0747 - binary_accuracy: 0.8864\nEpoch 175/200\n3891/3891 [==============================] - 0s 26us/step - loss: 0.0751 - binary_accuracy: 0.8864\nEpoch 176/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0747 - binary_accuracy: 0.8872\nEpoch 177/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0746 - binary_accuracy: 0.8885\nEpoch 178/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0747 - binary_accuracy: 0.8885\nEpoch 179/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0746 - binary_accuracy: 0.8882\nEpoch 180/200\n3891/3891 [==============================] - 0s 26us/step - loss: 0.0746 - binary_accuracy: 0.8877\nEpoch 181/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0747 - binary_accuracy: 0.8859\nEpoch 182/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0752 - binary_accuracy: 0.8864\nEpoch 183/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0751 - binary_accuracy: 0.8867\nEpoch 184/200\n3891/3891 [==============================] - 0s 23us/step - loss: 0.0748 - binary_accuracy: 0.8846\nEpoch 185/200\n3891/3891 [==============================] - 0s 20us/step - loss: 0.0744 - binary_accuracy: 0.8869\nEpoch 186/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0747 - binary_accuracy: 0.8841\nEpoch 187/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0744 - binary_accuracy: 0.8877\nEpoch 188/200\n3891/3891 [==============================] - 0s 21us/step - loss: 0.0742 - binary_accuracy: 0.8872\nEpoch 189/200\n3891/3891 [==============================] - 0s 16us/step - loss: 0.0739 - binary_accuracy: 0.8864\nEpoch 190/200\n3891/3891 [==============================] - 0s 27us/step - loss: 0.0740 - binary_accuracy: 0.8869\nEpoch 191/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0738 - binary_accuracy: 0.8892\nEpoch 192/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0743 - binary_accuracy: 0.8887\nEpoch 193/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0744 - binary_accuracy: 0.8869\nEpoch 194/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0746 - binary_accuracy: 0.8867\nEpoch 195/200\n3891/3891 [==============================] - 0s 17us/step - loss: 0.0742 - binary_accuracy: 0.8877\nEpoch 196/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0743 - binary_accuracy: 0.8879\nEpoch 197/200\n3891/3891 [==============================] - 0s 22us/step - loss: 0.0743 - binary_accuracy: 0.8856\nEpoch 198/200\n3891/3891 [==============================] - 0s 18us/step - loss: 0.0737 - binary_accuracy: 0.8864\nEpoch 199/200\n3891/3891 [==============================] - 0s 19us/step - loss: 0.0744 - binary_accuracy: 0.8867\nEpoch 200/200\n3891/3891 [==============================] - 0s 25us/step - loss: 0.0745 - binary_accuracy: 0.8890\n*ding*... Testing Accuracy on test set\n0.6536485097636177\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1613bf2fcee296b37754961dbf1aefad1bfe29fb"
      },
      "cell_type": "markdown",
      "source": "## Make the prediction ##"
    },
    {
      "metadata": {
        "_cell_guid": "9ed01b17-e2e8-4a24-8c9e-9c9db9019c6e",
        "_uuid": "f4461c5176b3f6840e3941c1233bf5ff77d04abe",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def format_dataset(df_sample):\n    df_pred = pd.DataFrame()\n    df_pred['Season'], df_pred['WTeamID'], df_pred['LTeamID'] = df_sample_sub['ID'].str.split('_', 2).str\n    df_pred = df_pred.astype(int) #DO I NEED THIS?\n    df_winseeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\n    df_lossseeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\n    df_preddummy = pd.merge(left=df_pred, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\n    df_predmerge = pd.merge(left=df_preddummy, right=df_lossseeds, on=['Season', 'LTeamID'])\n    df_predmerge['SeedDiff'] = df_predmerge.WSeed - df_predmerge.LSeed\n    df_predmerge = df_predmerge.rename(columns={'Season':'Year'})\n    df_predictions = df_predmerge[['WTeamID','LTeamID','SeedDiff']] # We really should add year to this somewhere\n    df_predictions['WTeamID'] = df_predictions['WTeamID'].astype(str)\n    df_predictions['LTeamID'] = df_predictions['LTeamID'].astype(str)\n    for x in df_predictions.columns:\n        df_predictions[x]=df_predictions[x].astype(df_preenc[x].dtypes.name)\n    return df_predictions.iloc[:, 0:3].values\n\n\n#Convert the prediction table to our format\ndf_predX = format_dataset(pd.read_csv(data_dir + 'SampleSubmissionStage1.csv'))\n#Encode the Predictions\ndf_predX[:, 0] = enc_1.transform(df_predX[:, 0])\ndf_predX[:, 1] = enc_2.transform(df_predX[:, 1])\ndf_predX = onehotencoder.transform(df_predX).toarray()\ndf_predX = sc.transform(df_predX)\n#Generate the predictions and save\ny_p = classifier.predict(df_predX)\nclipped_preds = np.clip(y_p, 0.0001, 0.999)\ndf_out=df_sample_sub\ndf_out.Pred = clipped_preds\ndf_out.to_csv('out.csv', index=False)\ndisplay(df_out)\nprint(df_out['Pred'].std())\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f838d4c9305eeadd92ce4af8d90c4349edc76a54"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}